{
 "cells": [
  {
   "source": [
    "# Projet UE11 – Calcul Différentiel\n",
    "LEBŒUF Antoine, HERNOT Anatole"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <b>Question 1</b>\n",
    "\n",
    "Soit $c \\in \\mathbb{R}$.\n",
    "On suppose que la fonction $f:\\mathbb{R}^2 \\to \\mathbb{R}$ est continue et vérifie\n",
    "$f(x_1, x_2) \\to +\\infty$ quand $\\|(x_1,x_2)\\| \\to +\\infty$.\n",
    "Que peut-on dire de l'ensemble de niveau $c$ de $f$ ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La fonction $f:\\mathbb{R}^2 \\to \\mathbb{R}$ est continue et $\\{c\\}$ est un fermé donc $\\underline{ f^{-1}(\\{c\\})\\, \\text{est fermé}}$.\n",
    "\n",
    "Par ailleurs, on a $f(x_1, x_2) \\to +\\infty$ quand $\\|(x_1,x_2)\\| \\to +\\infty$ donc :\n",
    "\n",
    "$$\\forall A \\in \\mathbb{R}, \\exists (x_1, x_2) \\in \\mathbb{R}^2 \\mid \\forall (y_1, y_2) \\in \\mathbb{R}^2, \\|(y_1, y_2)\\| > \\|(x_1, x_2)\\| \\Longrightarrow f(y_1, y_2) > A$$\n",
    "\n",
    "Ainsi si on choisit $A = c$, il existe un point $(x_1, x_2)$ de sorte que $\\forall (y_1, y_2) \\in \\mathbb{R}^2, \\|(y_1, y_2)\\| > \\|(x_1, x_2)\\| \\Longrightarrow f(y_1, y_2) > c$\n",
    "donc $\\mathrm f^{-1}(c) \\subset \\left\\{(y_1, y_2) \\in \\mathbb{R}^2 \\mid \\|(y_1,y_2)\\| < \\|(x_1,x_2)\\| \\right \\}$ qui est un ensemble borné et donc $\\underline{\\mathrm f^{-1}(c)\\, \\text{l'est aussi}}$.\n",
    "\n",
    "Enfin, comme on se trouve en dimension finie $\\mathrm f^{-1}(c)$ est un $\\underline{\\text{compact}}$ et c'est un fermé de $\\mathbb{R}^2$ donc c'est aussi $\\underline{\\text{un ensemble complet}}$ (important pour la convergence de la méthode de Newton).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "Dans la suite, la fonction $f$ est supposée continûment différentiable. On suppose également que le gradient $\\nabla f$ ne s'annule pas dans un voisinage du point $x_0 = (x_{10}, x_{20}) \\in \\mathbb{R}^2$. On pose alors\n",
    "$$\n",
    "p(x_1, x_2) := \\frac{\\partial_2 f(x_0)}{\\|\\nabla f(x_0)\\|} (x_1 - x_{10}) -\n",
    "\\frac{\\partial_1 f(x_0)}{\\|\\nabla f(x_0)\\|} (x_2 - x_{20}).\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <b>Question 2</b>\n",
    "Comment interpréter géométriquement le terme $p(x_1,x_2)$ ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On remarque que : \n",
    "$$p(x_1, x_2) := \\frac{\\partial_2 f(x_0)}{\\|\\nabla f(x_0)\\|} (x_1 - x_{10}) -\n",
    "\\frac{\\partial_1 f(x_0)}{\\|\\nabla f(x_0)\\|} (x_2 - x_{20}) = \n",
    "\\left(\\begin{matrix}\n",
    "\\partial_1 f(x_0) \\\\\n",
    "-\\partial_2 f(x_0)\n",
    "\\end{matrix}\\right)\n",
    "\\cdot\n",
    "\\left(\\begin{matrix}\n",
    "x_1 - x_{10} \\\\\n",
    "x_2 - x_{20}\n",
    "\\end{matrix}\\right)\n",
    "$$\n",
    "Graphiquement on se rend compte que le vecteur $ T_f(x_0) = \\left(\\begin{matrix}\n",
    "\\partial_1 f(x_0) \\\\\n",
    "-\\partial_2 f(x_0)\n",
    "\\end{matrix}\\right)$\n",
    "représente le vecteur tangentiel à la courbe de niveau de sorte que $(\\nabla f(x_0), T_f(x_0))$ forme une base orthogonale directe. Dès lors $p(x_1, x_2)$ représente la projection de $\\left(\\begin{matrix}\n",
    "x_1 - x_{10} \\\\\n",
    "x_2 - x_{20}\n",
    "\\end{matrix}\\right)$ sur ce vecteur tangentiel c'est-à-dire l'abscisse du point $(x_1, x_2)$ dans cette base \"locale\", semblable au repère de Fresnet en physique."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 3\n",
    "\n",
    "Montrer que dans un voisinage ouvert de $x_0$, on peut paramétriser l'ensemble de niveau $c:=f(x_0)$ au moyen de $p(x_1,x_2),$ c'est-à-dire qu'il existe un $\\varepsilon > 0$ et une fonction (continûment différentiable) $\\gamma :\\left]-\\varepsilon,\\varepsilon \\right[ \\to \\mathbb{R}^2$ tels que dans un voisinage ouvert de $x_0,$ $f(x_1,x_2) = c$ si et seulement si $(x_1, x_2) = \\gamma(t)$ où $t = p(x_1, x_2)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "On va appliquer le $\\underline{\\text{théorème des fonctions implicites}}$ à :\n",
    "$$\n",
    "\\begin{array}{ccccc}\n",
    "F & : & \\mathbb{R}^2 \\times \\mathbb{R} & \\to & \\mathbb{R}^2 \\\\\n",
    "& & (x_1, x_2, t) & \\longmapsto & (f(x_1, x_2) - c, p(x_1, x_2) - t)\n",
    "\\end{array}\n",
    "$$\n",
    "\n",
    "\n",
    "- On se place sur un voisinage ouvert $V$ de $x_0$ dans $\\mathbb{R}^3$.\n",
    "    \n",
    "    \n",
    "- La fonction F est bien continue différentiable sur cet ouvert car f l'est et $(x_1, x_2, t) \\longmapsto p(x_1, x_2) - t$ est une somme de fonctions affines.\n",
    "    \n",
    "    \n",
    "- On fixe $t \\in \\mathbb{R}$ alors pour tout $x \\in \\mathbb{R}^2, \\partial_x F(x) =  \n",
    "    \\left(\\begin{matrix}\n",
    "    \\partial_1 f(x) & \\partial_2 f(x) \\\\\n",
    "    \\frac{\\partial_2 f(x_0)}{\\|\\nabla f(x_0)\\|} & -\\frac{\\partial_1 f(x_0)}{\\|\\nabla f(x_0)\\|}\n",
    "    \\end{matrix}\\right)$\n",
    "    donc $\\det(\\partial_x F(x)) = -\\frac{\\partial_1 f(x) \\partial_1 f(x_0) + \\partial_2 f(x) \\partial_2 f(x_0)}{\\|\\nabla f(x_0)\\|}$. Or, en particulier, on sait que $\\det(\\partial_x F(x_0)) = -\\frac{\\partial_1 f(x_0)^2 + \\partial_2 f(x_0)^2}{\\|\\nabla f(x_0)\\|} = -1$ et $det$ est une application continue donc on peut trouver un nouveau voisinage $W \\in V$ sur lequel $\\forall x \\in W, det(\\partial_x F(x)) \\neq 0$ donc sur ce voisinage $\\partial_x F$ est inversible.\n",
    "    \n",
    "    \n",
    "- On connait une solution $(x_10, x_20, 0) \\in V$ qui vérifie $F(x_{10}, x_{20}, 0) = (0, 0)$\n",
    "\n",
    "\n",
    "Ainsi, il existe un $\\varepsilon > 0$ et une fonction (continûment différentiable) $\\gamma :\\left]-\\varepsilon,\\varepsilon \\right[ \\to \\mathbb{R}^2$ tels que dans un voisinage ouvert de $x_0,$ $f(x_1,x_2) = c$ si et seulement si $(x_1, x_2) = \\gamma(t)$ où $t = p(x_1, x_2)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "level_advanced"
    ]
   },
   "source": [
    "## Question 4\n",
    "\n",
    "Montrer que pour tout $t \\in \\left]-\\varepsilon, \\varepsilon \\right[$ :\n",
    "\n",
    "  - le vecteur $\\gamma'(t)$ est non nul (il fournit donc une tangente au chemin $\\gamma$),\n",
    "\n",
    "  - est orthogonal à $\\nabla f(\\gamma(t))$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "level_advanced"
    ]
   },
   "source": [
    "Le théorème des fonctions implicites nous donne aussi une information sur $\\gamma'$. En effet, pour $t \\in \\left]-\\varepsilon, \\varepsilon \\right[$ :\n",
    "\n",
    "$$d\\gamma(t) = \\gamma'(t) = {(\\partial_x F(x_1, x_2, t))}^{-1}\\partial_t F(x_1, x_2, t)$$\n",
    "avec $x = (x_1, x_2) = \\gamma(t)$.\n",
    "\n",
    "Or on a vu $\\partial_x F(x) =  \n",
    "\\begin{pmatrix}\n",
    "\\partial_1 f(x) & \\partial_2 f(x)\n",
    "\\\\\n",
    "\\frac{\\partial_2 f(x_0)}{\\|\\nabla f(x_0)\\|} & -\\frac{\\partial_1 f(x_0)}{\\|\\nabla f(x_0)\\|}\n",
    "\\end{pmatrix}$\n",
    "et\n",
    "$\\partial_t F(x) =\n",
    "\\begin{pmatrix}\n",
    "0 \\\\ -1\n",
    "\\end{pmatrix}$\n",
    "                        \n",
    "Donc, par calcul direct :\n",
    "$$\n",
    "\\gamma'(t)\n",
    "=\n",
    "-\\frac{\\|\\nabla f(x_0)\\|}{\\partial_1 f(x) \\partial_1 f(x_0) + \\partial_2 f(x) \\partial_2 f(x_0)}\n",
    "\\begin{pmatrix}\n",
    "-\\frac{\\partial_1 f(x_0)}{\\|\\nabla f(x_0)\\|} & -\\partial_2 f(x) \\\\\n",
    "-\\frac{\\partial_2 f(x_0)}{\\|\\nabla f(x_0)\\|} & \\partial_1 f(x)\n",
    "\\end{pmatrix}\n",
    "\\begin{pmatrix}\n",
    "0 \\\\ -1\n",
    "\\end{pmatrix}\n",
    "$$\n",
    "     \n",
    "$$\n",
    "\\gamma'(t) = -\\frac{\\|\\nabla f(x_0)\\|}{\\partial_1 f(x) \\partial_1 f(x_0) + \\partial_2 f(x) \\partial_2 f(x_0)}\n",
    "\\begin{pmatrix}\n",
    "\\partial_2 f(x) \\\\\n",
    "-\\partial_1 f(x)\n",
    "\\end{pmatrix}\n",
    "=\n",
    "\\frac{1}{det(\\partial_x F(x))}T_f(x)\n",
    "$$\n",
    "    \n",
    "Or $\\forall t \\in \\left]-\\varepsilon, \\varepsilon \\right[, T_f(x) \\neq 0$ car le gradient ne s'annule pas sur le voisinage de travail de $x_0$ donc $\\underline{\\gamma' \\, \\text{ne s'annule pas sur} \\ \\left]-\\varepsilon, \\varepsilon \\right[}$.\n",
    "\n",
    "Puis, encore par calcul direct pour $t \\in \\left]-\\varepsilon, \\varepsilon \\right[$ :\n",
    "$$\\langle \\nabla f(\\gamma(t)) \\mid \\gamma'(t) \\rangle = \\frac{1}{det(\\partial_x F(\\gamma(t)))}\\nabla f(\\gamma(t)) \\cdot T_f(\\gamma(t)) = 0$$ par définition de $T_f$ (cf Question 1). Par conséquent, $\\underline{\\text{pour tout} \\ t \\in \\left]-\\varepsilon,\\, \\varepsilon \\right[, \\gamma'(t) \\perp \\nabla f(\\gamma(t))}$."
   ]
  },
  {
   "source": [
    "## Question 5\n",
    "\n",
    "L'application à laquelle nous destinons la fonction `Newton` demande-t-elle une grande précision ?\n",
    "Choisir une valeur de `eps` qui semble raisonnable et justifier l'ordre de grandeur choisi."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "<réponse>"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 100\n",
    "eps = 10**-7"
   ]
  },
  {
   "source": [
    "### 5.1. Programmation préliminaire"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#   THIRD-PARTY LIBRARIES\n",
    "from typing import Callable\n",
    "\n",
    "import numpy as npy # importing the NumPy functions which are not overwritten by AutoGrad.NumPy\n",
    "\n",
    "import autograd\n",
    "import autograd.numpy as np\n",
    "\n",
    "#import pandas as pd\n",
    "#import matplotlib as mpl\n",
    "#import matplotlib.pyplot as plt\n",
    "#from IPython.display import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DiffFunctions():\n",
    "\n",
    "    def gradient(self, f:Callable):\n",
    "        g = autograd.grad\n",
    "        def grad_f(x, y):\n",
    "            x, y = float(x), float(y) # troubleshooting types (ugly)\n",
    "            return np.array([g(f, 0)(x, y), g(f, 1)(x, y)])\n",
    "        return grad_f\n",
    "\n",
    "\n",
    "    def jacobian(self, f:Callable):\n",
    "        j = autograd.jacobian\n",
    "        def J_f(x, y):\n",
    "            x, y = float(x), float(y) # troubleshooting types (ugly)\n",
    "            return np.array([ j(f, 0)(x, y) , j(f, 1)(x, y) ]) .T\n",
    "        return J_f"
   ]
  },
  {
   "source": [
    "### 5.2. Tâche 1\n",
    "Implémentation de la fonction `Newton`"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Newton(F:Callable, x0:float, y0:float, eps:float=eps, N:int=N) -> tuple:\n",
    "\n",
    "    \"\"\"\n",
    "    This function solves the equation F(x,y) = 0 around (x0,y0) using the Newton algorithm.\n",
    "\n",
    "    :param F: The function to solve for — it must necessarily have a multi-dimensional image in a np.ndarray type\n",
    "    :param x0: The initial x-axis coordinate\n",
    "    :param y0: The initial y-axis coordinate\n",
    "    :param eps: The acceptable precision of the algorithm\n",
    "    :param N: The maximum number of iterations (will raise an error if exceeded)\n",
    "\n",
    "    :returns: The solution to the equation F(x,y) = 0, to a precision of eps\n",
    "    \"\"\"\n",
    "\n",
    "    #   0. Troubleshooting types (ugly)\n",
    "    x0, y0 = float(x0), float(y0)\n",
    "\n",
    "    #   1. Defining the X0 point\n",
    "    X0 = np.array([x0, y0])\n",
    "\n",
    "    #   2. Generating the jacobian matrix of F (n-dimensional derivative)\n",
    "    jacF = DFunc.jacobian(F)\n",
    "\n",
    "    #   3. Running the method in a loop to refine the calculation\n",
    "    for iter_counter in range(N):\n",
    "\n",
    "        #   3.1. Inverting F's jacobian matrix\n",
    "        try: jacF_inv = npy.linalg.inv( jacF( *(X0.tolist()) ) )\n",
    "        except npy.linalg.linalg.LinAlgError: raise ValueError('The function to solve for has got a singular jacobian matrix.')\n",
    "\n",
    "        #   3.2. Dot product between jacF and F(X0)\n",
    "        F_dot = npy.dot( jacF_inv, F( *(X0.tolist()) ) )\n",
    "\n",
    "        #   3.3. Computing the new X point\n",
    "        X = X0 - F_dot\n",
    "\n",
    "        #   3.4. Exiting the function once the desired precision is reached\n",
    "        if npy.linalg.norm( X - X0 ) <= eps:\n",
    "            return tuple(X.tolist())\n",
    "\n",
    "        #   3.5. Performing end-of-loop actions\n",
    "        X0 = X.copy()\n",
    "\n",
    "    #   4. Raising an error when no solution is found and the max number of iterations is exceeded\n",
    "    raise ValueError(f'No convergence in {N} steps.')"
   ]
  },
  {
   "source": [
    "### 5.3. Tâche 2\n",
    "Test de la fonction `Newton`"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generating a grid to apply the function to\n",
    "\n",
    "x_range = (-5, 6)\n",
    "x_step  = 1\n",
    "y_range = (-5, 6)\n",
    "y_step  = 1\n",
    "\n",
    "lin_array = npy.mgrid[x_range[0] : x_range[1] : x_step , y_range[0] : y_range[1] : y_step]\n",
    "lin_array = lin_array.transpose(1, 2, 0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}